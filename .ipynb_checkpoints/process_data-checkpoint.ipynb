{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "devset_dir = \"factRuEval-2016/devset\"\n",
    "testset_dir = \"factRuEval-2016/testset\"\n",
    "result_dir = \"factRuEval-2016/results\"\n",
    "\n",
    "FactRu = namedtuple('FactRu', ['id', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(dir_path, filetype):\n",
    "    for filename in os.listdir(dir_path):\n",
    "        match = re.match('book_(\\d+)\\.'+filetype, filename)\n",
    "        if match:\n",
    "            id = int(match.group(1))\n",
    "            path = os.path.join(dir_path, filename)\n",
    "            with open(path) as f:\n",
    "                text = list()\n",
    "                for line in f:\n",
    "                    items = line.split()\n",
    "                    if len(items)>1:\n",
    "                        if filetype == 'tokens':\n",
    "                            text.append(items[3])\n",
    "                        else:\n",
    "                            entity = list()\n",
    "                            entity.append(items[1])\n",
    "                            counter = 0\n",
    "                            while items[counter+2] != '#':\n",
    "                                counter += 1\n",
    "                            ind_begin = counter+3\n",
    "                            while counter > 0:\n",
    "                                entity.append(items[ind_begin])\n",
    "                                counter -= 1\n",
    "                                ind_begin += 1\n",
    "                            text.append(entity)\n",
    "            yield FactRu(id, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens = list(read_dataset(devset_dir, 'tokens'))\n",
    "test_tokens = list(read_dataset(testset_dir, 'tokens'))\n",
    "train_objects = list(read_dataset(devset_dir, 'objects'))\n",
    "test_objects = list(read_dataset(testset_dir, 'objects'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['LocOrg', 'США'], ['Org', 'комитетом', 'ООН', 'комитетом'], ['Org', 'ООН'], ['Location', 'Женеве'], ['Org', 'министерства', 'иностранных', 'дел'], ['Person', 'Барри', 'Лоуенкрон'], ['Person', 'Barry', 'Lowenkron'], ['LocOrg', 'США'], ['Org', 'США', 'правительства'], ['Person', 'Лоуенкрон'], ['LocOrg', 'США'], ['Org', 'США', 'правительство'], ['Location', 'Абу-Грэйв'], ['Org', 'Абу-Грэйв', 'тюрьме'], ['Org', 'ЦРУ'], ['Org', 'Аль-Каиды'], ['LocOrg', 'США'], ['Org', 'США', 'делегация'], ['Org', 'Международная'], ['Org', 'Amnesty'], ['LocOrg', 'США'], ['Org', 'лагере', 'Гуантанамо'], ['Location', 'Гуантанамо'], ['Location', 'Кубе'], ['Location', 'Ираке'], ['Location', 'Афганистане'], ['LocOrg', 'США'], ['Org', 'ЦРУ'], ['Location', 'Македонии'], ['LocOrg', 'Германии'], ['Person', 'Халеда', 'эль-Масри'], ['Person', 'Khaled', 'el-Masri'], ['Location', 'Афганистан'], ['Org', 'Аль-Каиды'], ['Location', 'Сирию']]\n"
     ]
    }
   ],
   "source": [
    "print(train_objects[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_xy(tokens, objects):\n",
    "    xy_list = list()\n",
    "    tokens_list = list()\n",
    "    tags_list = list()\n",
    "    for i in range(len(tokens)):\n",
    "        tokens_list_for_id = tokens[i]\n",
    "        tags_list_for_id = [tags for tags in objects if tokens_list_for_id.id == tags.id]\n",
    "        if len(tags_list_for_id) == 0:\n",
    "            print(\"ERROR\")\n",
    "        #xy_list.append((tokens_list.text, tags_list[0].text))\n",
    "        tokens_list_for_id_text = tokens_list_for_id.text\n",
    "        tags_list_for_id_text = tags_list_for_id[0].text\n",
    "        prev_tag = None\n",
    "        tag = None\n",
    "        for ind in range(len(tokens_list_for_id_text)):\n",
    "            token = tokens_list_for_id_text[ind]\n",
    "            tokens_list.append(token)\n",
    "            for tags in tags_list_for_id_text:\n",
    "                match = [word for word in tags if word == token]\n",
    "                if len(match) > 0:\n",
    "                    tag = tags[0]\n",
    "            if tag == None:\n",
    "                tag = 'O'\n",
    "            elif tag == 'Person':\n",
    "                tag = 'PER'\n",
    "            elif tag == 'Org':\n",
    "                tag = 'ORG'\n",
    "            elif tag == 'Location':\n",
    "                tag = 'LOC'\n",
    "            else:\n",
    "                tag = 'MISC'\n",
    "            \n",
    "            if tag == prev_tag and tag != 'O':\n",
    "                prev_tag = tag\n",
    "                tag = 'I-' + tag\n",
    "            elif tag != 'O':\n",
    "                prev_tag = tag\n",
    "                tag = 'B-' + tag\n",
    "            else:\n",
    "                prev_tag = tag\n",
    "            tags_list.append(tag)\n",
    "            tag = None\n",
    "        if token == '.':\n",
    "            xy_list.append((tokens_list, tags_list, tags_list_for_id_text))\n",
    "            tokens_list = list()\n",
    "            tags_list = list()\n",
    "    return xy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113\n",
      "122\n"
     ]
    }
   ],
   "source": [
    "xy_list = make_xy(train_tokens, train_objects)\n",
    "print(len(xy_list))\n",
    "print(len(train_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
