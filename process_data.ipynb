{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "devset_dir = \"factRuEval-2016/devset\"\n",
    "testset_dir = \"factRuEval-2016/testset\"\n",
    "result_dir = \"factRuEval-2016/results\"\n",
    "\n",
    "FactRu = namedtuple('FactRu', ['id', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(dir_path, filetype):\n",
    "    for filename in os.listdir(dir_path):\n",
    "        match = re.match('book_(\\d+)\\.'+filetype, filename)\n",
    "        if match:\n",
    "            id = int(match.group(1))\n",
    "            path = os.path.join(dir_path, filename)\n",
    "            with open(path) as f:\n",
    "                text = list()\n",
    "                for line in f:\n",
    "                    items = line.split()\n",
    "                    if len(items)>1:\n",
    "                        if filetype == 'tokens':\n",
    "                            text.append(items[3])\n",
    "                        else:\n",
    "                            entity = list()\n",
    "                            entity.append(items[1])\n",
    "                            counter = 0\n",
    "                            while items[counter+2] != '#':\n",
    "                                counter += 1\n",
    "                            ind_begin = counter+3\n",
    "                            while counter > 0:\n",
    "                                entity.append(items[ind_begin])\n",
    "                                counter -= 1\n",
    "                                ind_begin += 1\n",
    "                            text.append(entity)\n",
    "            yield FactRu(id, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens = list(read_dataset(devset_dir, 'tokens'))\n",
    "test_tokens = list(read_dataset(testset_dir, 'tokens'))\n",
    "train_objects = list(read_dataset(devset_dir, 'objects'))\n",
    "test_objects = list(read_dataset(testset_dir, 'objects'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Правительство', 'Японии', 'выразило', 'решительный', 'протест', 'против', 'состоявшегося', 'в', 'пятницу', 'визита', 'российского', 'министра', 'обороны', ',', 'посетившего', 'южные', 'Курильские', 'острова', ',', 'которые', 'и', 'Япония', ',', 'и', 'Россия', 'считают', 'своими', '.', 'Четыре', 'острова', ',', 'которые', 'называются', 'Южными', 'Курилами', ',', 'и', 'которые', 'японцы', 'называют', 'Северными', 'территориями', ',', 'отошли', 'к', 'Советскому', 'Союзу', 'после', 'Второй', 'мировой', 'войны', '.', 'Территориальный', 'спор', 'вокруг', 'этих', 'островов', 'до', 'сих', 'пор', ',', 'через', '65', 'лет', 'после', 'окончания', 'военных', 'действий', ',', 'не', 'дает', 'двум', 'странам', 'заключить', 'мирное', 'соглашение', '.', 'Премьер-министр', 'Японии', 'Наото', 'Кан', 'назвал', 'посещение', 'двух', 'из', 'этих', 'островов', 'министром', 'обороны', 'России', 'Анатолием', 'Сердюковым', '«', 'в', 'высшей', 'степени', 'достойным', 'сожаления', '»', '.', 'Эта', 'поездка', 'состоялась', 'лишь', 'за', 'неделю', 'до', 'запланированного', 'визита', 'в', 'Москву', 'министра', 'иностранных', 'дел', 'Японии', 'Сейджи', 'Маехары', '.']\n"
     ]
    }
   ],
   "source": [
    "print(train_tokens[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['LocOrg', 'США'], ['Org', 'комитетом', 'ООН', 'комитетом'], ['Org', 'ООН'], ['Location', 'Женеве'], ['Org', 'министерства', 'иностранных', 'дел'], ['Person', 'Барри', 'Лоуенкрон'], ['Person', 'Barry', 'Lowenkron'], ['LocOrg', 'США'], ['Org', 'США', 'правительства'], ['Person', 'Лоуенкрон'], ['LocOrg', 'США'], ['Org', 'США', 'правительство'], ['Location', 'Абу-Грэйв'], ['Org', 'Абу-Грэйв', 'тюрьме'], ['Org', 'ЦРУ'], ['Org', 'Аль-Каиды'], ['LocOrg', 'США'], ['Org', 'США', 'делегация'], ['Org', 'Международная'], ['Org', 'Amnesty'], ['LocOrg', 'США'], ['Org', 'лагере', 'Гуантанамо'], ['Location', 'Гуантанамо'], ['Location', 'Кубе'], ['Location', 'Ираке'], ['Location', 'Афганистане'], ['LocOrg', 'США'], ['Org', 'ЦРУ'], ['Location', 'Македонии'], ['LocOrg', 'Германии'], ['Person', 'Халеда', 'эль-Масри'], ['Person', 'Khaled', 'el-Masri'], ['Location', 'Афганистан'], ['Org', 'Аль-Каиды'], ['Location', 'Сирию']]\n"
     ]
    }
   ],
   "source": [
    "print(train_objects[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ufal.udpipe import Model, Pipeline\n",
    "\n",
    "def tag_ud(text='Текст нужно передать функции в виде строки!', modelfile='udpipe_syntagrus.model'):\n",
    "    model = Model.load(modelfile)\n",
    "    pipeline = Pipeline(model, 'tokenize', Pipeline.DEFAULT, Pipeline.DEFAULT, 'conllu')\n",
    "    processed = pipeline.process(text) # обрабатываем текст, получаем результат в формате conllu\n",
    "    output = [l for l in processed.split('\\n') if not l.startswith('#')] # пропускаем строки со служебной информацией\n",
    "    tagged = [w.split('\\t')[2].lower() + '_' + w.split('\\t')[3] for w in output if w] # извлекаем из обработанного текста лемму и тэг\n",
    "#     tagged_propn = []\n",
    "#     propn  = []\n",
    "#     print(tagged)\n",
    "#     for t in tagged:\n",
    "#         if t.endswith('PROPN'):\n",
    "#             if propn:\n",
    "#                 propn.append(t)\n",
    "#             else:\n",
    "#                 propn = [t]\n",
    "#         else:\n",
    "#             if len(propn) > 1:\n",
    "#                 for x in propn:\n",
    "#                     #name = '::'.join([x.split('_')[0] for x in propn]) + '_PROPN'\n",
    "#                     tagged_propn.append(x)\n",
    "#             elif len(propn) == 1:\n",
    "#                 tagged_propn.append(propn[0])\n",
    "#             tagged_propn.append(t)\n",
    "#             propn = []\n",
    "    return tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_xy(tokens, objects):\n",
    "    xy_list = list()\n",
    "    tokens_list = list()\n",
    "    tokens_str = ''\n",
    "    tags_list = list()\n",
    "    new_tokens_list = list()\n",
    "    for i in range(len(tokens)):\n",
    "        print(i)\n",
    "        tokens_list_for_id = tokens[i]\n",
    "        tags_list_for_id = [tags for tags in objects if tokens_list_for_id.id == tags.id]\n",
    "        tokens_list_for_id_text = tokens_list_for_id.text\n",
    "        tags_list_for_id_text = tags_list_for_id[0].text\n",
    "        prev_tag = None\n",
    "        tag = None\n",
    "        for ind in range(len(tokens_list_for_id_text)):\n",
    "            token = tokens_list_for_id_text[ind]\n",
    "            tokens_str += token + ' '\n",
    "            for tags in tags_list_for_id_text:\n",
    "                match = [word for word in tags if word == token]\n",
    "                if len(match) > 0:\n",
    "                    tag = tags[0]\n",
    "            if tag == None:\n",
    "                tag = 'O'\n",
    "            elif tag == 'Person':\n",
    "                tag = 'PER'\n",
    "            elif tag == 'Org':\n",
    "                tag = 'ORG'\n",
    "            elif tag == 'Location' or tag =='LocOrg':\n",
    "                tag = 'LOC'\n",
    "            else:\n",
    "                tag = 'MISC'\t\t\t\n",
    "            if tag == prev_tag and tag != 'O':\n",
    "                prev_tag = tag\n",
    "                tag = 'I-' + tag\n",
    "            elif tag != 'O':\n",
    "                prev_tag = tag\n",
    "                tag = 'B-' + tag\n",
    "            else:\n",
    "                prev_tag = tag\n",
    "            tokens_list.append(token)\n",
    "            tags_list.append(tag)\n",
    "            tag = None\n",
    "            if token == '.':\n",
    "                new_tokens_list = tag_ud(tokens_str, 'rus_emb/'+'udpipe_syntagrus.model')\n",
    "                #print((new_tokens_list, tags_list, ))\n",
    "                print(len(tokens_list), len(new_tokens_list))\n",
    "                xy_list.append((new_tokens_list, tags_list,))\n",
    "                tokens_list = list()\n",
    "                new_tokens_list = list()\n",
    "                tags_list = list()\n",
    "                tokens_str = ''\n",
    "    return xy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "28 28\n",
      "24 24\n",
      "25 25\n",
      "23 23\n",
      "18 18\n",
      "1\n",
      "29 29\n",
      "45 45\n",
      "40 40\n",
      "32 32\n",
      "2\n",
      "18 18\n",
      "24 24\n",
      "16 16\n",
      "25 25\n",
      "7 7\n",
      "17 17\n",
      "9 9\n",
      "12 12\n",
      "15 15\n",
      "23 23\n",
      "31 31\n",
      "17 17\n",
      "31 31\n",
      "11 11\n",
      "19 19\n",
      "3\n",
      "19 19\n",
      "18 18\n",
      "28 28\n",
      "14 14\n",
      "25 25\n",
      "22 22\n",
      "13 13\n",
      "4 4\n",
      "4\n",
      "16 16\n",
      "35 35\n",
      "5\n",
      "40 41\n",
      "15 15\n",
      "12 12\n",
      "44 44\n",
      "15 15\n",
      "11 11\n",
      "18 18\n",
      "16 16\n",
      "6\n",
      "3 3\n",
      "16 16\n",
      "33 33\n",
      "21 21\n",
      "21 21\n",
      "24 24\n",
      "37 37\n",
      "12 12\n",
      "7\n",
      "31 31\n",
      "20 20\n",
      "28 28\n",
      "23 23\n",
      "36 36\n",
      "22 22\n",
      "2 2\n",
      "24 24\n",
      "22 22\n",
      "29 29\n",
      "17 17\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-34b759b50b86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxy_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxy_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-51de163dd22e>\u001b[0m in \u001b[0;36mmake_xy\u001b[0;34m(tokens, objects)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                 \u001b[0mnew_tokens_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtag_ud\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rus_emb/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'udpipe_syntagrus.model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m                 \u001b[0;31m#print((new_tokens_list, tags_list, ))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_tokens_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-33b3debef27c>\u001b[0m in \u001b[0;36mtag_ud\u001b[0;34m(text, modelfile)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtag_ud\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Текст нужно передать функции в виде строки!'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'udpipe_syntagrus.model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tokenize'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFAULT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFAULT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'conllu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# обрабатываем текст, получаем результат в формате conllu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "xy_list = make_xy(train_tokens, train_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['23_NUM', ':_PUNCT', '30_NUM', 'подстригль_VERB', 'дата_NOUN', '-центр_NOUN']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_ud(\"23:30 подстригли дата-центры\", 'rus_emb/'+'udpipe_syntagrus.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['23', '30', 'подстригли', 'дата', 'центры']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r\"[\\w']+|[.,!?;]\", \"23:30 подстригли дата-центры\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "embeddings_filepath='rus_emb/ruwikiruscorpora-nobigrams_upos_skipgram_300_5_2018.vec.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format(embeddings_filepath, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'что_SCONJ' in model.vocab"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
